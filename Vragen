Stijl:
- referentie voor randomized svd?
- referentie voor Gram met QR?
- hoe Engelse woorden gebruiken in Nederlandse tekst? cursief? te veel? bv. "Randomized SVD" als titel
- hoe spreken over ik, we, men, ...
- caption bij elke figuur en tabel? alleen bij figuren, alleen bij tabellen?
- optionele dingen in template: lijst van figuren, lijst van tabellen, lijst van afkortingen en symbolen?
- . of , in getallen

Inhoud:
- timings single-threaded of multi-threaded?

Inhoud, later:
- Gram-matrix met QR-decompositie: klopt?
- numerieke instabiliteit Gram-matrix?
- numerieke verbetering met QR bij Gram-matrix?
- steekproefgrootte bij randomized SVD?
- bespreking T-HOSVD nodig in achtergrond, of niet?

29/04/2019

Af:
- Inleveren in juni? Ok
- Welk algoritme voor lossless compressie datasets?
- Weinig ... gebruiken, betere formulering: onder meer A en B i.p.v. A, B, ...
- zlib, ... erg vreemd, maar een opsomming
- Welke kant van afbeelding afgehakt bij Pavia Centre
- QR algoritme: niet alleen trager, maar ook geen invloed op fout
- eventueel \cdot i.p.v. *
- symm. tridiag matrix eigenwaardenontbinding: erg snel, hoe snel? O(k^2) met referentie naar bv. boek van Demmel
- geef aan welke implementatie gebruikt wordt voor symmetrische tridiagonale matrix
- Referentie randomized SVD: door papers heen gaan en referenties volgen, specifieke versie, referentie naar literatuur
- Lanczos werkt goed, 200 naar 4 of 200 naar 6, zeker een valabele techniek, maar in dit geval niet precies genoeg
- eventueel bij Lanczos nog plots toevoegen met verdeling relatieve fout in functie van compressierang, bespreken dat een beetje hoger betekent dat men voor dezelfde fout een pakje verder moet gaan kijken op de rang-as vanwege de hyperbool-achtige vorm van de grafiek (ook verdeling van singuliere waarden)
- Grotere dataset, eventueel berg, rond ~1GB

Info:
- Waarom nut van tensor-gebaseerde technieken bij methodologie? Lijkt me meer iets voor inleiding.: Inleiding OK, bands zien er visueel erg soortgelijk uit, vandaar dat we misschien iets met tensor-gebaseerde technieken doen of iets anders dat de spectrale verbanden behoudt

Todo:

09/05/2019

Af:
- Bespreek aantal vrijheidsgraden orthogonale matrix aan begin na belang factormatrices bespreking
- Orthogonaliseer volledige kolommen expliciet na partiele of volledige hernormalizatie: eventueel testen, geen prioriteit
- Haal aan dat Givens-rotaties gebruikt kunnen worden om Q-matrix bij QR in halve ruimte op te slaan, maar moeilijk te gebruiken in Python, wordt gebruikt in LAPACK bij QR-functie (http://www.math.utah.edu/software/lapack/lapack-s/sgeqrf.html en http://www.math.utah.edu/software/lapack/lapack-s/sorgqr.html)
- Bitarray vermelden bij Methodologie->Implementatie
- Niet bitstring compressie, maar algemene lossless compressie
- Splits quantizatie en encodering + lossless compressie op
- Bijlage voor bitarray-aanpassingen

Todo:

Vragen:
- Referentie naar Stack overflow?
- Referenties voor code snippets? Momenteel alleen in source code zelf. Voorlopig alleen voor limiteren van geheugen, berekenen graycodes, berekenen Huffman codes, comprimeren Huffman-boom

24/05/2019

Af:
- Paginalimiet bij CW?
- Foute definitie lagen, corrigeer
- Verduidelijk definitie lagen, bijvoorbeeld algoritmische definitie: "tensor[i:, :i, :i] zonder tensor[:i - 1, :i - 1, :i - 1]", bijvoorbeeld met tekening voor kubus-tensor
- Vermeld dat code snippets gebruikt werden voor Gray-codes, Huffman-codes, ... van online op het einde van sectie 4.4.1: Implementatie
- Verwisselen Implementatie met Encoderingsmethoden
- Label grafieken met aantal quantizatiebits (bij ongequantiseerde lagen: één van de lijnen die op elkaar liggen)
- Verduidelijking bij sectie 4.2.2:
	- Orthogonale matrices kunnen compacter opgeslagen worden met reflectoren, maar we hebben Householder-reflectoren niet, dus we draaien opnieuw een QR-factorizatie
	- Tabel onduidelijk: ST-HOSVD naar "Referentie", N/A naar -, benadruk betekenis van "Quantizatie" en "Geen quantizatie"
- Sectie 4.2.1: Relatieve fout kolommen onduidelijk, vermeld formule
- Adaptief: overhead -> van de bomen
- BHC klein beetje verder uitwerken, niet zo duidelijk besproken
- Verduidelijken tabel 4.4.4, Huffman-code zonder bomen lijkt het beste
- Splits tabel op: kijk niet naar zonder bomen in één tabel, maak nieuwe tabel met Huffman-code, adaptief (met BHC) adaptief (zonder BHC) met kolommen: geheugen voor data zelf, geheugen voor bomen, geheugen totaal
- tabel 4.11: voeg kolom toe voor relatieve grootte t.o.v. beste, absolute grootte niet even belangrijk
- verduidelijk kolommen/reflectoren bij quantisatie - factormatrices

Todo:

Vragen:
- Hoeveel bijlagen? Momenteel 35 pagina's.

02/06/2019

Af:
- Leg tensor trains verder uit
- Draai Mauna Kea compressietijd-experimenten
- Extra definitie tensor trains
- Fiche masterproef? Ja, CW behoort tot de opleidingen waar dit moet.

Todo:

Vragen:
- Kleuren voor links en referenties: in digitale versie, in gedrukte versie?
- Vergelijking gevonden met paper https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6310664, lijkt beter, moet dit vermeld worden?

24/06/2019

Vragen:
- Bibliografie op einde?
